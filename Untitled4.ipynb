{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import itertools\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine.sql.almaden import Sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db =  Sql(\"datacast2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopKeywordList = stopwords.words('english')\n",
    "stopKeywordList.append(\"https\")\n",
    "stopKeywordList.append(\"http\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wodud\\PycharmProjects\\DAlmaden\\kano\\source\\fonts\\NanumBarunGothic.ttf\n"
     ]
    }
   ],
   "source": [
    "cwd = str(Path.cwd())\n",
    "fontname = \"NanumBarunGothic.ttf\"\n",
    "font_path = f\"{cwd}\\\\kano\\\\source\\\\fonts\\\\{fontname}\"\n",
    "print(font_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayWordCloud(dict, background_color='white', width=1600, height=800):\n",
    "    wordcloud = WordCloud(font_path=font_path,\n",
    "                         stopwords = stopKeywordList,background_color=background_color,width=width,height=height).generate_from_frequencies(dict)\n",
    "    plt.figure(figsize = (15,10))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyaze_tweets(df_coord, keyword, brand):\n",
    "    len_df = len(df_coord)\n",
    "    word_class_list = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "    pos = list()\n",
    "    words = list()\n",
    "    remove_list = pos_tag(word_tokenize(keyword.lower()))\n",
    "    for idx in df_coord.index:\n",
    "        pos.extend(pos_tag(word_tokenize(df_coord.at[idx,'content'])))\n",
    "\n",
    "    for p in pos:\n",
    "        if p[0] not in remove_list and p[1] in word_class_list:  # nltk\n",
    "            words.append(p[0].lower())\n",
    "                \n",
    "    counter = Counter(words)\n",
    "    most_common_noun = counter.most_common()\n",
    "    most_common_noun = list(filter(lambda c: len(c[0]) >= 2, most_common_noun))\n",
    "    most_common_noun = list(filter(lambda c: c[0] not in stopKeywordList, most_common_noun))\n",
    "    most_common_noun = list(filter(lambda c: c[1] >= 0, most_common_noun))\n",
    "    keyword_bog = pd.DataFrame(most_common_noun, columns=['keyword', 'count'])\n",
    "    keyword_bog.to_excel(f\"{str(cwd)}/kano/results/buzz/{keyword}_{loc}_{brand}_{len_df}.xlsx\")\n",
    "    return dict(most_common_noun),len_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'Home Battery'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 'usa'\n",
    "\n",
    "\n",
    "df_coord = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '{} near:\"{}\"'.format(keyword,loc)).get_items(), 6000))[['user', 'date','content']]\n",
    "df_coord['search_keyword'] = keyword\n",
    "df_coord['user_location'] = df_coord['user'].apply(lambda x: x['location'])\n",
    "df_coord['date'] = df_coord['date'].apply(lambda a: pd.to_datetime(a).date())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tesla = r'.*(tesla)'\n",
    "p_lg = r'.*(lg chem)'\n",
    "p_sonnen = r'.*(sonnen)'\n",
    "p_generac = r'.*(generac)'\n",
    "p_byd = r'.*(byd)'\n",
    "df_coord['content'] = df_coord['content'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coord_tesla = df_coord[df_coord['content'].str.match(p_tesla,flags=re.MULTILINE)]\n",
    "df_coord_lg = df_coord[df_coord['content'].str.match(p_lg,flags=re.MULTILINE)]\n",
    "df_coord_sonnen = df_coord[df_coord['content'].str.match(p_sonnen,flags=re.MULTILINE)]\n",
    "df_coord_generac = df_coord[df_coord['content'].str.match(p_generac,flags=re.MULTILINE)]\n",
    "df_coord_byd = df_coord[df_coord['content'].str.match(p_byd,flags=re.MULTILINE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>search_keyword</th>\n",
       "      <th>user_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user, date, content, search_keyword, user_location]\n",
       "Index: []"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coord_tesla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_keyword = \"sonnen home battery\"\n",
    "channel = 'twitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = db.select('crawl_task','task_id',f'keyword=\\\"{search_keyword}\\\" and channel=\\\"{channel}\\\"')[0]['task_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24519\n"
     ]
    }
   ],
   "source": [
    "print(task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insert = df_coord_sonnen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in df_insert.index :\n",
    "    post_date = df_insert.at[idx,'date']\n",
    "    text = df_insert.at[idx,'content']\n",
    "    title = df_insert.at[idx,'user']\n",
    "    print(title)\n",
    "    db.insert('crawl_contents',\n",
    "                                 task_id = task_id,\n",
    "                                text= text,\n",
    "                                post_date= post_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tesla,_ = analyaze_tweets(df_coord_tesla,keyword,'tesla' )\n",
    "dict_lg,_ = analyaze_tweets(df_coord_lg,keyword,'lg' )\n",
    "dict_sonnen,_ = analyaze_tweets(df_coord_sonnen,keyword,'sonnen' )\n",
    "dict_generac,_ = analyaze_tweets(df_coord_generac,keyword,'generac' )\n",
    "dict_byd,_ = analyaze_tweets(df_coord_byd,keyword,'byd' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'displayWordCloud' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ba94d619646a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplayWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_byd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'displayWordCloud' is not defined"
     ]
    }
   ],
   "source": [
    "db.select(\"crawl_task\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dalmaden",
   "language": "python",
   "name": "dalmaden"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
